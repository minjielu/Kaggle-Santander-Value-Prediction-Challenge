{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 3.69 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read datasets\n",
    "data = pd.read_csv('./train.csv')\n",
    "# test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlog_data = np.log1p(data[features])\\ntest_data = np.log1p(test[features])\\nlog_target = np.log1p(data['target'])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "log_data = np.log1p(data[features])\n",
    "test_data = np.log1p(test[features])\n",
    "log_target = np.log1p(data['target'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlog_target = np.log1p(data['target'])\\nprint(np.min(log_target))\\nprint(np.max(log_target))\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "log_target = np.log1p(data['target'])\n",
    "print(np.min(log_target))\n",
    "print(np.max(log_target))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_min = 30.0\\ndata_max = -1.0\\ntest_min = 30.0\\ntest_max = -1.0\\nfor column in features:\\n    data_min = min(data_min,np.min(log_data.loc[log_data[column] != 0,column]))\\n    data_max = max(data_max,np.max(log_data.loc[log_data[column] != 0,column]))\\n    test_min = min(test_min,np.min(test_data.loc[test_data[column] != 0,column]))\\n    test_max = max(test_max,np.max(test_data.loc[test_data[column] != 0,column]))\\nprint(data_min)\\nprint(data_max)\\nprint(test_min)\\nprint(test_max)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_min = 30.0\n",
    "data_max = -1.0\n",
    "test_min = 30.0\n",
    "test_max = -1.0\n",
    "for column in features:\n",
    "    data_min = min(data_min,np.min(log_data.loc[log_data[column] != 0,column]))\n",
    "    data_max = max(data_max,np.max(log_data.loc[log_data[column] != 0,column]))\n",
    "    test_min = min(test_min,np.min(test_data.loc[test_data[column] != 0,column]))\n",
    "    test_max = max(test_max,np.max(test_data.loc[test_data[column] != 0,column]))\n",
    "print(data_min)\n",
    "print(data_max)\n",
    "print(test_min)\n",
    "print(test_max)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 318 ms, total: 22.5 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = [f for f in data.columns if f not in ['target', 'ID']]\n",
    "\n",
    "# This function generates histogram of each row in datasets\n",
    "def to_hist_func(row):\n",
    "    count = row[row != 0].shape[0]\n",
    "    hist = []\n",
    "    # Add fine histogram\n",
    "    for x in np.arange(8,17,0.2):\n",
    "        hist.append(row[(row < x+1) & (row >= x)].shape[0])\n",
    "    # Add coarse histogram\n",
    "    for x in np.arange(8,17,1):\n",
    "        hist.append(row[(row < x+2) & (row >= x)].shape[0])\n",
    "    hist.append(row[(row < 23) & (row >= 20)].shape[0])\n",
    "    hist.append(count) # Add number of nonzero values\n",
    "    hist.append(skew(row)) # Add skewness\n",
    "    return hist\n",
    "\n",
    "# Generate histograms for train data\n",
    "hist_data = np.apply_along_axis(\n",
    "    func1d=to_hist_func, \n",
    "    axis=1, \n",
    "    arr=(np.log1p(data[features])).astype(float)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = ['hist'+str(f) for f in np.arange(len(hist_data[0]))]\n",
    "# hist_data_df = pd.DataFrame(hist_data,columns=column_names)\n",
    "# hist_data[hist_data > 0]\n",
    "# data_new = pd.concat([data,hist_data_df],axis = 1)\n",
    "# data_new = data_new.drop(['ID','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 59s, sys: 4.79 s, total: 6min 4s\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate histograms for test data\n",
    "hist_test = np.apply_along_axis(\n",
    "    func1d=to_hist_func, \n",
    "    axis=1, \n",
    "    arr=(np.log1p(test[features])).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ba1682884c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# hist_data[hist_data > 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist_test_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# hist_test_df = pd.DataFrame(hist_test,columns=column_names)\n",
    "# hist_data[hist_data > 0]\n",
    "# test_new = pd.concat([test,hist_test_df],axis = 1)\n",
    "# test_new = test_new.drop(['ID','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 scores : TRN 0.9902 TST 1.3218\n",
      "Fold 2 scores : TRN 0.9724 TST 1.3689\n",
      "Fold 3 scores : TRN 0.9844 TST 1.3214\n",
      "Fold 4 scores : TRN 0.9779 TST 1.3389\n",
      "Fold 5 scores : TRN 0.9900 TST 1.2774\n",
      "Full OOF score : 1.3260\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "oof_preds = np.zeros(data.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "for n_fold, (trn_, val_) in enumerate(folds.split(data)):\n",
    "    reg = ExtraTreesRegressor(\n",
    "        n_estimators=1500, \n",
    "        max_features=.8,                       \n",
    "        max_depth=12, \n",
    "        min_samples_leaf=5, \n",
    "        random_state=3, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Fit Extra Trees\n",
    "    reg.fit(hist_data[trn_], np.log1p(data['target'].iloc[trn_]))\n",
    "    # Get OOF predictions\n",
    "    oof_preds[val_] = reg.predict(hist_data[val_])\n",
    "    # Update TEST predictions\n",
    "    sub_preds += reg.predict(hist_test) / folds.n_splits\n",
    "    # Display fold's score\n",
    "    print('Fold %d scores : TRN %.4f TST %.4f'\n",
    "          % (n_fold + 1,\n",
    "             mean_squared_error(np.log1p(data['target'].iloc[trn_]),\n",
    "                                reg.predict(hist_data[trn_])) ** .5,\n",
    "             mean_squared_error(np.log1p(data['target'].iloc[val_]),\n",
    "                                reg.predict(hist_data[val_])) ** .5))\n",
    "          \n",
    "print('Full OOF score : %.4f' % (mean_squared_error(np.log1p(data['target']), oof_preds) ** .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customerid = data['ID']\n",
    "#result = pd.Series(gbm.predict(test_x),name='target')\n",
    "#result = pd.Series(oof_preds,name='target')\n",
    "#result = pd.concat([customerid,result],axis=1)\n",
    "#min_value = train_y.min()\n",
    "#result.loc[result['target'] < min_value,'target'] = min_value\n",
    "#result.to_csv('Santander_train_2.csv',index=False)\n",
    "\n",
    "# Generate submission file\n",
    "test['target'] = np.expm1(sub_preds)\n",
    "test[['ID', 'target']].to_csv('histogram_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result['target_ob'] = np.log1p(data['target'])\n",
    "# result['difference'] = (result['target']-result['target_ob'])**2\n",
    "# result_2 = pd.read_csv('../Results/Santander_train_1.csv')\n",
    "# result['target_2'] = result_2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows',5000)\n",
    "# result[(result['target'] < 15) & (result['target'] > 14)]\n",
    "# result_3 = []\n",
    "# for ind, row in result_2.iterrows():\n",
    "    # result_3.append((result.iloc[ind]['target']+result_2.iloc[ind]['target'])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Full Out-Of-Fold score : %9.6f' \n",
    "      # % (mean_squared_error(np.log1p(data['target']), result_3) ** .5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
