{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, learning_curve, validation_curve, GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import skew, kurtosis\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.89 s, sys: 277 ms, total: 5.16 s\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv('./train.csv')\n",
    "# test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['nonzero_cnt'] = (data != 0).sum(axis=1)-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(data['nonzero_cnt'],kde=False,rug=True)\n",
    "# plt.xlim(0,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_split = []\\nnew_ID = []\\nnew_target = []\\nID_count = 1\\nfor ind, row in data.iterrows():\\n    row = row[(data.columns != 'nonzero_cnt') & (data.columns != 'ID') & (data.columns != 'target')]\\n    row = row[row != 0]\\n    row = row.values\\n    if row.shape[0] < 50:\\n        new_sample = row\\n        new_sample = np.pad(new_sample,(50-row.shape[0],0),'constant', constant_values=(0, 0))\\n        train_split.append(new_sample)\\n        sample_index = 'sample'+str(ID_count)\\n        new_ID.append(sample_index)\\n        new_target.append(data.iloc[ind]['target'])\\n        ID_count += 1\\n        continue\\n    num_split = np.floor(row.shape[0]/50)+1\\n    extra = (row.shape[0] % 50)+50\\n    i = 0\\n    while i < num_split-2:\\n        new_sample = row[i*50:(i+1)*50]\\n        train_split.append(new_sample)\\n        sample_index = 'sample'+str(ID_count)\\n        new_ID.append(sample_index)\\n        new_target.append(data.iloc[ind]['target'])\\n        ID_count += 1\\n        i += 1\\n    if extra == 50:\\n        new_sample = row[i*50:(i+1)*50]\\n        train_split.append(new_sample)\\n        sample_index = 'sample'+str(ID_count)\\n        new_ID.append(sample_index)\\n        new_target.append(data.iloc[ind]['target'])\\n        ID_count += 1\\n    else:\\n        new_sample = row[i*50:int(i*50+np.ceil(extra/2))]\\n        new_sample = np.pad(new_sample,(int(50-np.ceil(extra/2)),0),'constant', constant_values=(0, 0))\\n        train_split.append(new_sample)\\n        sample_index = 'sample'+str(ID_count)\\n        new_ID.append(sample_index)\\n        new_target.append(data.iloc[ind]['target'])\\n        ID_count += 1\\n        new_sample = row[int(i*50+np.ceil(extra/2)):]\\n        new_sample = np.pad(new_sample,(50-int(extra-np.ceil(extra/2)),0),'constant', constant_values=(0, 0))\\n        train_split.append(new_sample)\\n        sample_index = 'sample'+str(ID_count)\\n        new_ID.append(sample_index)\\n        new_target.append(data.iloc[ind]['target'])\\n        ID_count += 1\\n        \\nnew_columns = []\\nfor i in np.arange(50):\\n    new_columns.append('column'+str(i))\\n    \\ntrain_new = pd.DataFrame(train_split,columns=new_columns)\\ntrain_new['ID'] = new_ID\\ntrain_new['target'] = new_target\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_split = []\n",
    "new_ID = []\n",
    "new_target = []\n",
    "ID_count = 1\n",
    "for ind, row in data.iterrows():\n",
    "    row = row[(data.columns != 'nonzero_cnt') & (data.columns != 'ID') & (data.columns != 'target')]\n",
    "    row = row[row != 0]\n",
    "    row = row.values\n",
    "    if row.shape[0] < 50:\n",
    "        new_sample = row\n",
    "        new_sample = np.pad(new_sample,(50-row.shape[0],0),'constant', constant_values=(0, 0))\n",
    "        train_split.append(new_sample)\n",
    "        sample_index = 'sample'+str(ID_count)\n",
    "        new_ID.append(sample_index)\n",
    "        new_target.append(data.iloc[ind]['target'])\n",
    "        ID_count += 1\n",
    "        continue\n",
    "    num_split = np.floor(row.shape[0]/50)+1\n",
    "    extra = (row.shape[0] % 50)+50\n",
    "    i = 0\n",
    "    while i < num_split-2:\n",
    "        new_sample = row[i*50:(i+1)*50]\n",
    "        train_split.append(new_sample)\n",
    "        sample_index = 'sample'+str(ID_count)\n",
    "        new_ID.append(sample_index)\n",
    "        new_target.append(data.iloc[ind]['target'])\n",
    "        ID_count += 1\n",
    "        i += 1\n",
    "    if extra == 50:\n",
    "        new_sample = row[i*50:(i+1)*50]\n",
    "        train_split.append(new_sample)\n",
    "        sample_index = 'sample'+str(ID_count)\n",
    "        new_ID.append(sample_index)\n",
    "        new_target.append(data.iloc[ind]['target'])\n",
    "        ID_count += 1\n",
    "    else:\n",
    "        new_sample = row[i*50:int(i*50+np.ceil(extra/2))]\n",
    "        new_sample = np.pad(new_sample,(int(50-np.ceil(extra/2)),0),'constant', constant_values=(0, 0))\n",
    "        train_split.append(new_sample)\n",
    "        sample_index = 'sample'+str(ID_count)\n",
    "        new_ID.append(sample_index)\n",
    "        new_target.append(data.iloc[ind]['target'])\n",
    "        ID_count += 1\n",
    "        new_sample = row[int(i*50+np.ceil(extra/2)):]\n",
    "        new_sample = np.pad(new_sample,(50-int(extra-np.ceil(extra/2)),0),'constant', constant_values=(0, 0))\n",
    "        train_split.append(new_sample)\n",
    "        sample_index = 'sample'+str(ID_count)\n",
    "        new_ID.append(sample_index)\n",
    "        new_target.append(data.iloc[ind]['target'])\n",
    "        ID_count += 1\n",
    "        \n",
    "new_columns = []\n",
    "for i in np.arange(50):\n",
    "    new_columns.append('column'+str(i))\n",
    "    \n",
    "train_new = pd.DataFrame(train_split,columns=new_columns)\n",
    "train_new['ID'] = new_ID\n",
    "train_new['target'] = new_target\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = train_new\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = train_new\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_features = ['f190486d6', 'c47340d97', 'eeb9cd3aa', '66ace2992', 'e176a204a',\n",
    "        '491b9ee45', '1db387535', 'c5a231d81', '0572565c2', '024c577b9',\n",
    "        '15ace8c9f', '23310aa6f', '9fd594eec', '58e2e02e6', '91f701ba2',\n",
    "        'adb64ff71', '2ec5b290f', '703885424', '26fc93eb7', '6619d81fc',\n",
    "        '0ff32eb98', '70feb1494', '58e056e12', '1931ccfdd', '1702b5bf0',\n",
    "        '58232a6fb', '963a49cdc', 'fc99f9426', '241f0f867', '5c6487af1',\n",
    "        '62e59a501', 'f74e8f13d', 'fb49e4212', '190db8488', '324921c7b',\n",
    "        'b43a7cfd5', '9306da53f', 'd6bb78916', 'fb0f5dbfe', '6eef030c1']\n",
    "\n",
    "features = [f for f in data.columns if f not in ['target', 'ID']]\n",
    "magic_features_loc = [features.index(x) for x in magic_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'magic_features_loc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mto_hist_func\u001b[0;34m(row)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'magic_features_loc' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = [f for f in data.columns if f not in ['target', 'ID']]\n",
    "\n",
    "def to_hist_func(row):\n",
    "    count = row[row != 0].shape[0]\n",
    "    hist = []\n",
    "    # Add Santander 46 magic features.\n",
    "    hist.extend(row[magic_features_loc])\n",
    "    row = row[row != 0]\n",
    "    hist.append(np.min(row))\n",
    "    hist.append(np.percentile(row,10))\n",
    "    hist.append(np.percentile(row,20))\n",
    "    hist.append(np.percentile(row,25))\n",
    "    hist.append(np.percentile(row,30))\n",
    "    hist.append(np.percentile(row,40))\n",
    "    hist.append(np.percentile(row,50))\n",
    "    hist.append(np.percentile(row,60))\n",
    "    hist.append(np.percentile(row,70))\n",
    "    hist.append(np.percentile(row,75))\n",
    "    hist.append(np.percentile(row,80))\n",
    "    hist.append(np.percentile(row,90))\n",
    "    hist.append(np.max(row))\n",
    "    hist.append(np.mean(row))\n",
    "    hist.append(np.median(row))\n",
    "    hist.append(np.sum(row))\n",
    "    # Add fine histogram.\n",
    "    # for x in np.arange(8,17,0.2):\n",
    "        # hist.append(row[(row < x+1) & (row >= x)].shape[0])\n",
    "    # Add coarse histogram.\n",
    "    # for x in np.arange(8,17,1):\n",
    "        # hist.append(row[(row < x+2) & (row >= x)].shape[0])\n",
    "    # hist.append(row[(row < 23) & (row >= 20)].shape[0])\n",
    "    # Add count of nonzero values\n",
    "    hist.append(count)\n",
    "    # Add the skewness of the distribution\n",
    "    hist.append(skew(row))\n",
    "    # Add the kurtosiss of the distribution\n",
    "    hist.append(kurtosis(row))\n",
    "    '''\n",
    "    # Add the same statistical features for unique values\n",
    "    row_unique = np.unique(row)\n",
    "    hist.append(np.min(row_unique))\n",
    "    hist.append(np.percentile(row_unique,10))\n",
    "    hist.append(np.percentile(row_unique,20))\n",
    "    hist.append(np.percentile(row_unique,25))\n",
    "    hist.append(np.percentile(row_unique,30))\n",
    "    hist.append(np.percentile(row_unique,40))\n",
    "    hist.append(np.percentile(row_unique,50))\n",
    "    hist.append(np.percentile(row_unique,60))\n",
    "    hist.append(np.percentile(row_unique,70))\n",
    "    hist.append(np.percentile(row_unique,75))\n",
    "    hist.append(np.percentile(row_unique,80))\n",
    "    hist.append(np.percentile(row_unique,90))\n",
    "    hist.append(np.max(row_unique))\n",
    "    for x in np.arange(8,17,0.2):\n",
    "        hist.append(row_unique[(row_unique < x+1) & (row_unique >= x)].shape[0])\n",
    "    for x in np.arange(8,17,1):\n",
    "        hist.append(row_unique[(row_unique < x+2) & (row_unique >= x)].shape[0])\n",
    "    hist.append(row_unique[(row_unique < 23) & (row_unique >= 20)].shape[0])\n",
    "    hist.append(len(row_unique)) # Add the number of unique values.\n",
    "    hist.append(skew(row_unique))\n",
    "    hist.append(kurtosis(row_unique))\n",
    "    '''\n",
    "    pdrow = pd.Series(row)\n",
    "    # Add the three most frequent values. If there is not enough unique values, zeroes are used instead.\n",
    "    unique_values = pdrow.value_counts()\n",
    "    hist.append(unique_values.index[0])\n",
    "    if unique_values.shape[0] == 1:\n",
    "        hist.extend([0,0])\n",
    "        return hist\n",
    "    hist.append(unique_values.index[1])\n",
    "    if unique_values.shape[0] == 2:\n",
    "        hist.extend([0])\n",
    "        return hist\n",
    "    hist.append(unique_values.index[2])\n",
    "    return hist\n",
    "\n",
    "hist_data = np.apply_along_axis(\n",
    "    func1d=to_hist_func, \n",
    "    axis=1, \n",
    "    arr=(np.log1p(data[features])).astype(float)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_test = np.apply_along_axis(\n",
    "    func1d=to_hist_func, \n",
    "    axis=1, \n",
    "    arr=(np.log1p(test[features])).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features = [f for f in test.columns if f not in ['ID']]\n",
    "\n",
    "def to_hist_func(row):\n",
    "    count = row[row != 0].shape[0]\n",
    "    hist = []\n",
    "    for x in np.arange(8,17,0.2):\n",
    "        hist.append(row[(row < x+1) & (row >= x)].shape[0])\n",
    "    for x in np.arange(8,17,1):\n",
    "        hist.append(row[(row < x+2) & (row >= x)].shape[0])\n",
    "    hist.append(row[(row < 23) & (row >= 20)].shape[0])\n",
    "    hist.append(count)\n",
    "    hist.append(skew(row))\n",
    "    return hist\n",
    "\n",
    "hist_test = np.apply_along_axis(\n",
    "    func1d=to_hist_func, \n",
    "    axis=1, \n",
    "    arr=(np.log1p(test[features])).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_own_score(ground_truth,predictions):\n",
    "    return (mean_squared_error(ground_truth,predictions) ** .5)\n",
    "    \n",
    "score = make_scorer(my_own_score,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExTree_params = {'n_estimators':[1000,1500,2000],\n",
    "                'max_features':[.3,.6,.8],\n",
    "                'max_depth':[5,10,15],\n",
    "                'min_samples_leaf':[5,10,15,20],\n",
    "                }\n",
    "\n",
    "gsExTree = GridSearchCV(ExtraTreesRegressor(random_state=3,n_jobs=-1),param_grid = ExTree_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsExTree.fit(hist_data,np.log1p(data['target']))\n",
    "print(gsExTree.best_params_)\n",
    "print(gsExTree.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_params = {'n_neighbors':[5,10,15,20],\n",
    "              'weights':['uniform','distance'],\n",
    "              'algorithm':['ball_tree','kd_tree'],\n",
    "              }\n",
    "\n",
    "gsKNN = GridSearchCV(KNeighborsRegressor(n_jobs=-1),param_grid = KNN_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsKNN.fit(hist_data,np.log1p(data['target']))\n",
    "print(gsKNN.best_params_)\n",
    "print(gsKNN.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SVR_params = {'n_neighbors':[1000,1500,2000],\n",
    "                'weights':[.3,.6,.8],\n",
    "                'algorithm':[5,10,15],\n",
    "                }\n",
    "\n",
    "gsSVR = GridSearchCV(SVR(n_jobs=-1),param_grid = SVR_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsSVR.fit(hist_data,np.log1p(data['target']))\n",
    "gsSVR.best_params_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_params = {'criterion':['mse','friedman_mse','mae'],\n",
    "            'splitter':['best','random'],\n",
    "            'min_samples_leaf':[5,10,15,20],\n",
    "            }\n",
    "\n",
    "gsDT = GridSearchCV(DecisionTreeRegressor(),param_grid = DT_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsDT.fit(hist_data,np.log1p(data['target']))\n",
    "print(gsDT.best_params_)\n",
    "print(gsDT.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_params = {'n_estimators':[1000,1500,2000],\n",
    "            'max_features':[.3,.6,.8],\n",
    "            'max_depth':[5,10,15],\n",
    "            'min_samples_leaf':[5,10,15,20],\n",
    "            }\n",
    "\n",
    "gsRF = GridSearchCV(RandomForestRegressor(random_state=3,n_jobs=-1),param_grid = RF_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsRF.fit(hist_data,np.log1p(data['target']))\n",
    "print(gsRF.best_params_)\n",
    "print(gsRF.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADBoost_params = {'n_estimators':[100,300,500],\n",
    "                    'learning_rate':[.05,.1,.3,.5],\n",
    "                    'loss':['linear','square','exponential'],\n",
    "                    }\n",
    "\n",
    "gsADBoost = GridSearchCV(AdaBoostRegressor(random_state=3),param_grid = ADBoost_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsADBoost.fit(hist_data,np.log1p(data['target']))\n",
    "print(gsADBoost.best_params_)\n",
    "print(gsADBoost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'num_leaves': [30,58,70],\n",
    "    'subsample': [0.4,0.6143,0.85],\n",
    "    'colsample_bytree': [0.4,0.6453,0.85],\n",
    "    'max_depth': [5,10,15],\n",
    "    'learning_rate': [0.05,.1,.3,.5],\n",
    "}\n",
    "\n",
    "mylgb = lgb.LGBMRegressor(objective='regression', random_state=3, boosting_type='gbdt', seed=3, min_child_weight=np.power(10, -0.1477), reg_lambda=np.power(10, 1.7570), reg_alpha=np.power(10, -2.2887), min_split_gain=np.power(10, -2.5988))\n",
    "\n",
    "gsLGBoost = GridSearchCV(mylgb,param_grid = lgb_params,scoring=score,n_jobs=4,verbose=1)\n",
    "gsLGBoost.fit(hist_data,np.log1p(data['target']))\n",
    "print(gsLGBoost.best_params_)\n",
    "print(gsLGBoost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best MSE: -1.3963\n",
      "Best params: {'learning_rate': 0.41632686502344207, 'max_bin': 285, 'max_depth': 49, 'min_child_samples': 16, 'min_child_weight': 1, 'min_split_gain': 0.0035709054039510754, 'n_estimators': 72, 'num_leaves': 85, 'reg_alpha': 3.040308671030701e-07, 'reg_lambda': 180.50090239517365, 'subsample_freq': 1}\n",
      "\n",
      "Model #2\n",
      "Best MSE: -1.3963\n",
      "Best params: {'learning_rate': 0.41632686502344207, 'max_bin': 285, 'max_depth': 49, 'min_child_samples': 16, 'min_child_weight': 1, 'min_split_gain': 0.0035709054039510754, 'n_estimators': 72, 'num_leaves': 85, 'reg_alpha': 3.040308671030701e-07, 'reg_lambda': 180.50090239517365, 'subsample_freq': 1}\n",
      "\n",
      "Model #3\n",
      "Best MSE: -1.3963\n",
      "Best params: {'learning_rate': 0.41632686502344207, 'max_bin': 285, 'max_depth': 49, 'min_child_samples': 16, 'min_child_weight': 1, 'min_split_gain': 0.0035709054039510754, 'n_estimators': 72, 'num_leaves': 85, 'reg_alpha': 3.040308671030701e-07, 'reg_lambda': 180.50090239517365, 'subsample_freq': 1}\n",
      "\n",
      "Model #4\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #5\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #6\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #7\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #8\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #9\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #10\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #11\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #12\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #13\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #14\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #15\n",
      "Best MSE: -1.341\n",
      "Best params: {'learning_rate': 0.043185018415720616, 'max_bin': 691, 'max_depth': 12, 'min_child_samples': 24, 'min_child_weight': 2, 'min_split_gain': 0.01010379642720492, 'n_estimators': 59, 'num_leaves': 24, 'reg_alpha': 6.595188375981598e-06, 'reg_lambda': 0.07021302379333542, 'subsample_freq': 1}\n",
      "\n",
      "Model #16\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #17\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #18\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #19\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #20\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #21\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #22\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #23\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #24\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #25\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #26\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #27\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #28\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #29\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #30\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #31\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #32\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #33\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #34\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #35\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #36\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #37\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #38\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #39\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #40\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #41\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #42\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #43\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #44\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #45\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #46\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #47\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #48\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #49\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #50\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #51\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #52\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #53\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #54\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #55\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #56\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #57\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #58\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #59\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #60\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #61\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #62\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #63\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #64\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #65\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #66\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #67\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #68\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #69\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #70\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #71\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #72\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #73\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #74\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #75\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #76\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #77\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #78\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #79\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #80\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #81\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #82\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #83\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #84\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #85\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #86\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #87\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #88\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #89\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #90\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #91\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #92\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #93\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #94\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #95\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #96\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #97\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #98\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #99\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n",
      "Model #100\n",
      "Best MSE: -1.337\n",
      "Best params: {'learning_rate': 0.034396482189098944, 'max_bin': 1000, 'max_depth': 7, 'min_child_samples': 18, 'min_child_weight': 5, 'min_split_gain': 0.005475890955639273, 'n_estimators': 146, 'num_leaves': 23, 'reg_alpha': 6.406243771595693e-08, 'reg_lambda': 0.022998236675593222, 'subsample_freq': 0}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=KFold(n_splits=5, random_state=1, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "       n_jobs=-1, num_leaves=31, objective='regression', random_state=3,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid=True, n_iter=100, n_jobs=1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=3,\n",
       "       refit=True, return_train_score=False,\n",
       "       scoring=make_scorer(my_own_score, greater_is_better=False),\n",
       "       search_spaces={'learning_rate': (0.01, 1.0, 'log-uniform'), 'num_leaves': (10, 100), 'max_depth': (0, 50), 'min_child_samples': (0, 50), 'max_bin': (100, 1000), 'subsample_freq': (0, 10), 'min_child_weight': (0, 10), 'reg_lambda': (1e-09, 1000, 'log-uniform'), 'reg_alpha': (1e-09, 1.0, 'log-uniform'), 'n_estimators': (50, 150), 'min_split_gain': (0.001, 10.0, 'log-uniform')},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bsLGBoost.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bsLGBoost.best_params_)\n",
    "    print('Model #{}\\nBest MSE: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bsLGBoost.best_score_, 4),\n",
    "        bsLGBoost.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bsLGBoost.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")\n",
    "\n",
    "search_params = {\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'num_leaves': (10, 100),      \n",
    "    'max_depth': (0, 50),\n",
    "    'min_child_samples': (0, 50),\n",
    "    'max_bin': (100, 1000),\n",
    "    'subsample_freq': (0, 10),\n",
    "    'min_child_weight': (0, 10),\n",
    "    'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "    'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "    'n_estimators': (50, 150),\n",
    "    'min_split_gain': (0.001, 10.0, 'log-uniform')\n",
    "}\n",
    "\n",
    "mylgb = lgb.LGBMRegressor(objective='regression', random_state=3)\n",
    "\n",
    "bsLGBoost = BayesSearchCV(mylgb, search_spaces=search_params,scoring=score, cv=KFold(n_splits=5,shuffle=True,random_state=1), n_jobs=1, n_iter=100, verbose=0, refit=True, random_state=3)\n",
    "\n",
    "bsLGBoost.fit(hist_data,np.log1p(data['target']),callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best MSE: -1.339\n",
      "Best params: {'max_depth': 40, 'max_features': 0.2849290713064093, 'min_samples_leaf': 20, 'n_estimators': 966}\n",
      "\n",
      "Model #2\n",
      "Best MSE: -1.322\n",
      "Best params: {'max_depth': 50, 'max_features': 0.2530668595918294, 'min_samples_leaf': 6, 'n_estimators': 1441}\n",
      "\n",
      "Model #3\n",
      "Best MSE: -1.322\n",
      "Best params: {'max_depth': 50, 'max_features': 0.2530668595918294, 'min_samples_leaf': 6, 'n_estimators': 1441}\n",
      "\n",
      "Model #4\n",
      "Best MSE: -1.322\n",
      "Best params: {'max_depth': 50, 'max_features': 0.2530668595918294, 'min_samples_leaf': 6, 'n_estimators': 1441}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bsET.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bsET.best_params_)\n",
    "    print('Model #{}\\nBest MSE: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bsET.best_score_, 4),\n",
    "        bsET.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bsET.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name+\"_cv_results.csv\")\n",
    "\n",
    "search_params = {\n",
    "    'n_estimators': (500,2000),\n",
    "    'max_features': (0.1, 1),      \n",
    "    'max_depth': (0, 50),\n",
    "    'min_samples_leaf': (1, 20),\n",
    "}\n",
    "\n",
    "myET = ExtraTreesRegressor(random_state=3)\n",
    "\n",
    "bsET = BayesSearchCV(myET, search_spaces=search_params,scoring=score, cv=KFold(n_splits=5,shuffle=True,random_state=1), n_jobs=1, n_iter=100, verbose=0, refit=True, random_state=3)\n",
    "\n",
    "bsET.fit(hist_data,np.log1p(data['target']),callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(regressor, title, x, y, score):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(regressor, x, y, scoring=score, train_sizes = np.linspace(0.1,1.0,7), cv = 5)\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of samples')\n",
    "    plt.ylabel('score')\n",
    "    plt.grid()\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myET = ExtraTreesRegressor(n_estimators=1000, max_features=.8, max_depth=10, min_samples_leaf=5, random_state=3, n_jobs=-1)\n",
    "myKNN = KNeighborsRegressor(n_neighbors=20, weights='distance', algorithm='kd_tree', n_jobs=-1)\n",
    "myDT = DecisionTreeRegressor(criterion='friedman_mse', splitter='random', min_samples_leaf=15)\n",
    "myRF = RandomForestRegressor(n_estimators=2000, max_features=.3, max_depth=10, min_samples_leaf=5,random_state=3,n_jobs=-1)\n",
    "myADBoost = AdaBoostRegressor(n_estimators=100, learning_rate=0.05, loss='linear', random_state=3)\n",
    "mylgb = lgb.LGBMRegressor(num_leaves=58,subsample=.4,colsample_bytree=.4,max_depth=10,learning_rate=0.05,objective='regression',random_state=3,boosting_type='gbdt',seed=3,min_child_weight=np.power(10,-0.1477),reg_lambda=np.power(10,1.7570),reg_alpha=np.power(10,-2.2887),min_split_gain=np.power(10,-2.5988))\n",
    "'''\n",
    "plot_learning_curve(myET,'ExtraTrees regressor learning curve',hist_data,np.log1p(data['target']),score)\n",
    "plot_learning_curve(myKNN,'KNN regressor learning curve',hist_data,np.log1p(data['target']),score)\n",
    "plot_learning_curve(myDT,'DecisionTree regressor learning curve',hist_data,np.log1p(data['target']),score)\n",
    "plot_learning_curve(myRF,'RandomForest regressor learning curve',hist_data,np.log1p(data['target']),score)\n",
    "plot_learning_curve(myADBoost,'AdaBoost regressor learning curve',hist_data,np.log1p(data['target']),score)\n",
    "plot_learning_curve(mylgb,'LightGBM regressor learning curve',hist_data,np.log1p(data['target']),score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "RF_preds = np.zeros(hist_test.shape[0])\n",
    "\n",
    "for n_fold, (trn_, val_) in enumerate(folds.split(hist_data)):\n",
    "    myRF.fit(hist_data[trn_],np.log1p(data.iloc[trn_]['target']))\n",
    "    RF_preds += myRF.predict(hist_test) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = np.expm1(RF_preds)\n",
    "test[['ID', 'target']].to_csv('randomforest_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meta_features(regressor,x,y,z):\n",
    "    folds = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "    oof_preds = np.zeros(x.shape[0])\n",
    "    test_preds = np.zeros(z.shape[0])\n",
    "    \n",
    "    for n_fold, (trn_, val_) in enumerate(folds.split(x)):\n",
    "        regressor.fit(x[trn_],y[trn_])\n",
    "        oof_preds[val_] = regressor.predict(hist_data[val_])\n",
    "        test_preds += regressor.predict(z) / folds.n_splits\n",
    "        \n",
    "    return oof_preds,test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_meta,ET_test_meta = generate_meta_features(myET,hist_data,np.log1p(data['target']),hist_test)\n",
    "KNN_meta,KNN_test_meta = generate_meta_features(myKNN,hist_data,np.log1p(data['target']),hist_test)\n",
    "DT_meta,DT_test_meta = generate_meta_features(myDT,hist_data,np.log1p(data['target']),hist_test)\n",
    "RF_meta,RF_test_meta = generate_meta_features(myRF,hist_data,np.log1p(data['target']),hist_test)\n",
    "ADBoost_meta,ADBoost_test_meta = generate_meta_features(myADBoost,hist_data,np.log1p(data['target']),hist_test)\n",
    "LGB_meta,LGB_test_meta = generate_meta_features(mylgb,hist_data,np.log1p(data['target']),hist_test)\n",
    "ET_meta = pd.Series(ET_meta,name='ET_meta')\n",
    "KNN_meta = pd.Series(KNN_meta,name='KNN_meta')\n",
    "DT_meta = pd.Series(DT_meta,name='DT_meta')\n",
    "RF_meta = pd.Series(RF_meta,name='RF_meta')\n",
    "ADBoost_meta = pd.Series(ADBoost_meta,name='ADBoost_meta')\n",
    "LGB_meta = pd.Series(LGB_meta,name='LGB_meta')\n",
    "ET_test_meta = pd.Series(ET_test_meta,name='ET_meta')\n",
    "KNN_test_meta = pd.Series(KNN_test_meta,name='KNN_meta')\n",
    "DT_test_meta = pd.Series(DT_test_meta,name='DT_meta')\n",
    "RF_test_meta = pd.Series(RF_test_meta,name='RF_meta')\n",
    "ADBoost_test_meta = pd.Series(ADBoost_test_meta,name='ADBoost_meta')\n",
    "LGB_test_meta = pd.Series(LGB_test_meta,name='LGB_meta')\n",
    "\n",
    "train_meta=pd.concat([ET_meta,KNN_meta,DT_meta,RF_meta,ADBoost_meta,LGB_meta],axis=1)\n",
    "test_meta=pd.concat([ET_test_meta,KNN_test_meta,DT_test_meta,RF_test_meta,ADBoost_test_meta,LGB_test_meta],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = (ET_test_meta+KNN_test_meta+RF_test_meta+ADBoost_test_meta+LGB_test_meta)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "oof_preds = np.zeros(train_meta.shape[0])\n",
    "sub_preds = np.zeros(test_meta.shape[0])\n",
    "\n",
    "for n_fold, (trn_, val_) in enumerate(folds.split(train_meta)):\n",
    "    '''\n",
    "    reg = ExtraTreesRegressor(\n",
    "        n_estimators=1500, \n",
    "        max_features=.8,                       \n",
    "        max_depth=12, \n",
    "        min_samples_leaf=5, \n",
    "        random_state=3, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    '''\n",
    "    reg = lgb.LGBMRegressor(\n",
    "        num_leaves=60,\n",
    "        subsample=.4,\n",
    "        colsample_bytree=.6,\n",
    "        max_depth=2,\n",
    "        learning_rate=0.1,\n",
    "        objective='regression',\n",
    "        random_state=3,\n",
    "        boosting_type='gbdt',\n",
    "        seed=3,\n",
    "        min_child_weight=np.power(10,-0.1477),\n",
    "        reg_lambda=np.power(10,1.7570),\n",
    "        reg_alpha=np.power(10,-2.2887),\n",
    "        min_split_gain=np.power(10,-2.5988)\n",
    "    )\n",
    "    # Fit Extra Trees\n",
    "    reg.fit(train_meta.iloc[trn_], np.log1p(data['target'].iloc[trn_]))\n",
    "    # Get OOF predictions\n",
    "    oof_preds[val_] = reg.predict(train_meta.iloc[val_])\n",
    "    # Update TEST predictions\n",
    "    sub_preds += reg.predict(test_meta) / folds.n_splits\n",
    "    # Display fold's score\n",
    "    print('Fold %d scores : TRN %.4f TST %.4f'\n",
    "          % (n_fold + 1,\n",
    "             mean_squared_error(np.log1p(data['target'].iloc[trn_]),\n",
    "                                reg.predict(train_meta.iloc[trn_])) ** .5,\n",
    "             mean_squared_error(np.log1p(data['target'].iloc[val_]),\n",
    "                                reg.predict(train_meta.iloc[val_])) ** .5))\n",
    "          \n",
    "print('Full OOF score : %.4f' % (mean_squared_error(np.log1p(data['target']), oof_preds) ** .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 scores : TRN 1.0411 TST 1.3293\n",
      "Fold 2 scores : TRN 1.0299 TST 1.3706\n",
      "Fold 3 scores : TRN 1.0365 TST 1.3355\n",
      "Fold 4 scores : TRN 1.0360 TST 1.3373\n",
      "Fold 5 scores : TRN 1.0502 TST 1.3124\n",
      "Full OOF score : 1.3372\n"
     ]
    }
   ],
   "source": [
    "# for cv test\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "oof_preds = np.zeros(hist_data.shape[0])\n",
    "sub_preds = np.zeros(hist_test.shape[0])\n",
    "\n",
    "for n_fold, (trn_, val_) in enumerate(folds.split(hist_data)):\n",
    "    '''\n",
    "    reg = ExtraTreesRegressor(\n",
    "        n_estimators=1441, \n",
    "        max_features=.25,                       \n",
    "        max_depth=50, \n",
    "        min_samples_leaf=6, \n",
    "        random_state=3, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Best parameters after grid search.\n",
    "    reg = lgb.LGBMRegressor(\n",
    "        num_leaves=60,\n",
    "        subsample=.4,\n",
    "        colsample_bytree=.6,\n",
    "        max_depth=2,\n",
    "        learning_rate=0.1,\n",
    "        objective='regression',\n",
    "        random_state=3,\n",
    "        boosting_type='gbdt',\n",
    "        seed=3,\n",
    "        min_child_weight=np.power(10,-0.1477),\n",
    "        reg_lambda=np.power(10,1.7570),\n",
    "        reg_alpha=np.power(10,-2.2887),\n",
    "        min_split_gain=np.power(10,-2.5988)\n",
    "    )\n",
    "    '''\n",
    "    reg = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        random_state=3,\n",
    "        learning_rate=0.034396482189098944,\n",
    "        max_bin=1000,\n",
    "        max_depth=7,\n",
    "        min_child_samples=18,\n",
    "        min_child_weight=5,\n",
    "        boosting_type='gbdt',\n",
    "        min_split_gain=0.005475890955639273,\n",
    "        n_estimators=146,\n",
    "        num_leaves=23,\n",
    "        reg_lambda=0.022998236675593222\n",
    "    )\n",
    "    # Best parameters after Bayes search.\n",
    "    # Fit Extra Trees\n",
    "    reg.fit(hist_data[trn_], np.log1p(data['target'].iloc[trn_]))\n",
    "    # Update TEST predictions\n",
    "    sub_preds += reg.predict(hist_test) / folds.n_splits    \n",
    "    # Get OOF predictions\n",
    "    oof_preds[val_] = reg.predict(hist_data[val_])\n",
    "    # Display fold's score\n",
    "    print('Fold %d scores : TRN %.4f TST %.4f'\n",
    "          % (n_fold + 1,\n",
    "             mean_squared_error(np.log1p(data['target'].iloc[trn_]),\n",
    "                                reg.predict(hist_data[trn_])) ** .5,\n",
    "             mean_squared_error(np.log1p(data['target'].iloc[val_]),\n",
    "                                reg.predict(hist_data[val_])) ** .5))\n",
    "          \n",
    "print('Full OOF score : %.4f' % (mean_squared_error(np.log1p(data['target']), oof_preds) ** .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customerid = data['ID']\n",
    "#result = pd.Series(gbm.predict(test_x),name='target')\n",
    "#result = pd.Series(oof_preds,name='target')\n",
    "#result = pd.concat([customerid,result],axis=1)\n",
    "#min_value = train_y.min()\n",
    "#result.loc[result['target'] < min_value,'target'] = min_value\n",
    "#result.to_csv('Santander_train_2.csv',index=False)\n",
    "\n",
    "\n",
    "test['target'] = np.expm1(sub_preds)\n",
    "test[['ID', 'target']].to_csv('new_predictions_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
