{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load libraries for analysis and visualization\n",
    "import pandas as pd # collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "import numpy as np  # foundational package for scientific computing\n",
    "import re           # Regular expression operations\n",
    "import matplotlib.pyplot as plt # Collection of functions for scientific and publication-ready visualization\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py     # Open source library for composing, editing, and sharing interactive data visualization \n",
    "from matplotlib import pyplot\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning libraries\n",
    "import sys\n",
    "sys.path.append('/Users/minjielu/anaconda3/envs/python/lib/python3.5/site-packages')\n",
    "\n",
    "import xgboost as xgb  # Implementation of gradient boosted decision trees designed for speed and performance that is dominative competitive machine learning\n",
    "import seaborn as sns  # Visualization library based on matplotlib, provides interface for drawing attractive statistical graphics\n",
    "\n",
    "import sklearn         # Collection of machine learning algorithms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report, precision_recall_curve, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "#test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_corr = []\n",
    "for column in train.columns:\n",
    "    if column != 'ID' and column != 'target':\n",
    "        train_1 = train[train[column] != 0][['target',column]]\n",
    "        corr_tmp = train_1.corr()\n",
    "        nonzero_corr.append([corr_tmp.loc['target',column],train_1.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_label = list(train.columns)\n",
    "column_label.pop(0)\n",
    "column_label.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_corr = pd.DataFrame(nonzero_corr,columns=['target','nonzero_cnt'],index=column_label)\n",
    "#nonzero_corr = nonzero_corr.sort_values(['target'])\n",
    "pd.set_option('display.max_rows',5000)\n",
    "#nonzero_corr\n",
    "#nonzero_corr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['target']\n",
    "train_x = train.loc[:,(train.columns !='ID') & (train.columns != 'target')].loc[:,((nonzero_corr['target'] > 100) | (nonzero_corr['target'] < 0)) & (nonzero_corr['nonzero_cnt'] > 200)]\n",
    "test_x = test.loc[:,(test.columns != 'ID') & (test.columns != 'target')].loc[:,((nonzero_corr['target'] > 100) | (nonzero_corr['target'] < 0)) & (nonzero_corr['nonzero_cnt'] > 200)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def fit_predict(data, y, test):\n",
    "    # Create folds\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # Init predictions\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    oof_preds = np.zeros(data.shape[0])\n",
    "    # Convert to lightgbm Dataset\n",
    "    dtrain = lgb.Dataset(data=data, label=np.log1p(y), free_raw_data=False)\n",
    "    # Construct dataset so that we can use slice()\n",
    "    dtrain.construct()\n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'num_leaves': 58,\n",
    "        'subsample': 0.6143,\n",
    "        'colsample_bytree': 0.6453,\n",
    "        'min_split_gain': np.power(10, -2.5988),\n",
    "        'reg_alpha': np.power(10, -2.2887),\n",
    "        'reg_lambda': np.power(10, 1.7570),\n",
    "        'min_child_weight': np.power(10, -0.1477),\n",
    "        'verbose': -1,\n",
    "        'seed': 3,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'metric': 'l2',\n",
    "    }\n",
    "    # Run KFold\n",
    "    for trn_idx, val_idx in folds.split(data):\n",
    "        # Train lightgbm\n",
    "        clf = lgb.train(\n",
    "            params=lgb_params,\n",
    "            train_set=dtrain.subset(trn_idx),\n",
    "            valid_sets=dtrain.subset(val_idx),\n",
    "            num_boost_round=10000, \n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "        # Predict Out Of Fold and Test targets\n",
    "        # Using lgb.train, predict will automatically select the best round for prediction\n",
    "        oof_preds[val_idx] = clf.predict(dtrain.data.iloc[val_idx])\n",
    "        sub_preds += clf.predict(test.loc[:,(test.columns != 'ID')]) / folds.n_splits\n",
    "        # Display current fold score\n",
    "        print(mean_squared_error(np.log1p(y.iloc[val_idx]), \n",
    "                                 oof_preds[val_idx]) ** .5)\n",
    "    # Display Full OOF score (square root of a sum is not the sum of square roots)\n",
    "    print('Full Out-Of-Fold score : %9.6f' \n",
    "          % (mean_squared_error(np.log1p(y), oof_preds) ** .5))\n",
    "\n",
    "    return oof_preds, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.752921\n",
      "[100]\tvalid_0's l2: 0.575302\n",
      "[150]\tvalid_0's l2: 0.520611\n",
      "[200]\tvalid_0's l2: 0.498929\n",
      "[250]\tvalid_0's l2: 0.490558\n",
      "[300]\tvalid_0's l2: 0.486854\n",
      "[350]\tvalid_0's l2: 0.48428\n",
      "[400]\tvalid_0's l2: 0.484683\n",
      "[450]\tvalid_0's l2: 0.482592\n",
      "[500]\tvalid_0's l2: 0.483072\n",
      "[550]\tvalid_0's l2: 0.483542\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's l2: 0.482501\n",
      "0.6946227718573611\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.74156\n",
      "[100]\tvalid_0's l2: 0.550661\n",
      "[150]\tvalid_0's l2: 0.497541\n",
      "[200]\tvalid_0's l2: 0.477754\n",
      "[250]\tvalid_0's l2: 0.469117\n",
      "[300]\tvalid_0's l2: 0.46285\n",
      "[350]\tvalid_0's l2: 0.459035\n",
      "[400]\tvalid_0's l2: 0.457217\n",
      "[450]\tvalid_0's l2: 0.456334\n",
      "[500]\tvalid_0's l2: 0.456454\n",
      "[550]\tvalid_0's l2: 0.45672\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid_0's l2: 0.455857\n",
      "0.6751719932721164\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.725414\n",
      "[100]\tvalid_0's l2: 0.571005\n",
      "[150]\tvalid_0's l2: 0.534194\n",
      "[200]\tvalid_0's l2: 0.518713\n",
      "[250]\tvalid_0's l2: 0.514133\n",
      "[300]\tvalid_0's l2: 0.509093\n",
      "[350]\tvalid_0's l2: 0.507677\n",
      "[400]\tvalid_0's l2: 0.50599\n",
      "[450]\tvalid_0's l2: 0.505767\n",
      "[500]\tvalid_0's l2: 0.506327\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's l2: 0.50569\n",
      "0.7111188746259723\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.677632\n",
      "[100]\tvalid_0's l2: 0.529576\n",
      "[150]\tvalid_0's l2: 0.499226\n",
      "[200]\tvalid_0's l2: 0.491332\n",
      "[250]\tvalid_0's l2: 0.486058\n",
      "[300]\tvalid_0's l2: 0.483903\n",
      "[350]\tvalid_0's l2: 0.481095\n",
      "[400]\tvalid_0's l2: 0.480928\n",
      "[450]\tvalid_0's l2: 0.479849\n",
      "[500]\tvalid_0's l2: 0.479361\n",
      "[550]\tvalid_0's l2: 0.478973\n",
      "[600]\tvalid_0's l2: 0.478874\n",
      "[650]\tvalid_0's l2: 0.478538\n",
      "[700]\tvalid_0's l2: 0.479469\n",
      "Early stopping, best iteration is:\n",
      "[640]\tvalid_0's l2: 0.478382\n",
      "0.6916519250983311\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's l2: 0.728408\n",
      "[100]\tvalid_0's l2: 0.542413\n",
      "[150]\tvalid_0's l2: 0.495934\n",
      "[200]\tvalid_0's l2: 0.482196\n",
      "[250]\tvalid_0's l2: 0.477672\n",
      "[300]\tvalid_0's l2: 0.474574\n",
      "[350]\tvalid_0's l2: 0.473874\n",
      "[400]\tvalid_0's l2: 0.475141\n",
      "Early stopping, best iteration is:\n",
      "[347]\tvalid_0's l2: 0.473523\n",
      "0.688130053839233\n",
      "Full Out-Of-Fold score :  0.692238\n"
     ]
    }
   ],
   "source": [
    "[oof_preds, subpreds] = fit_predict(train_x_2,train_y_2,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "oofpreds = pd.Series(oof_preds,name='pre_target')\n",
    "train_y = train_y.rename('target')\n",
    "train_y_1 = pd.concat([oofpreds,train_y],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_1['ratio'] = np.sqrt((train_y_1['pre_target']-np.log1p(train_y_1['target']))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_2 = train_y_1.loc[train_y_1['ratio'] < 1.2,'target']\n",
    "train_x_2 = train_x.loc[train_y_1['ratio'] < 1.2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2729"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.7,\n",
       "       colsample_bytree=0.7, gamma=0.002, grow_policy='lossguide',\n",
       "       learning_rate=0.02, max_delta_step=0, max_depth=8, max_leaves=31,\n",
       "       min_child_weight=5, missing=None, n_estimators=1000, n_jobs=-1,\n",
       "       nthread=None, objective='reg:linear', random_state=42,\n",
       "       reg_alpha=0.002, reg_lambda=1.0, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8, tree_method='hist')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "    'max_depth': 8, \n",
    "    'learning_rate': 0.02, \n",
    "    'n_estimators': 1000, \n",
    "    'silent': True, \n",
    "    'objective': 'reg:linear', \n",
    "    'booster': 'gbtree', \n",
    "    'n_jobs': -1, \n",
    "    'gamma': 0.002,\n",
    "    'min_child_weight': 5, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.7, \n",
    "    'colsample_bylevel': 0.7, \n",
    "    'reg_alpha': 0.002, \n",
    "    'reg_lambda': 1.0, \n",
    "    'random_state': 42}\n",
    "\n",
    "params['tree_method'] = 'hist'\n",
    "params['grow_policy'] = 'lossguide'\n",
    "params['max_leaves']  = 31\n",
    "\n",
    "test_x = test.loc[:,(test.columns != 'ID') & (test.columns != 'target')].loc[:,((nonzero_corr['target'] >= 0.2) | (nonzero_corr['target'] <= -0.2)) & (nonzero_corr['nonzero_cnt'] > 20)]\n",
    "\n",
    "gbm = xgb.XGBRegressor(**params)\n",
    "gbm.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerid = test['ID']\n",
    "#result = pd.Series(gbm.predict(test_x),name='target')\n",
    "result = pd.Series(np.expm1(subpreds),name='target')\n",
    "result = pd.concat([customerid,result],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_value = train_y.min()\n",
    "#result.loc[result['target'] < min_value,'target'] = min_value\n",
    "result.to_csv('Santander_result_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
