{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 4993)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_leak(df, new_cols, cols, lag=0):\n",
    "    d1 = df[new_cols[:-lag-2]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2 = df[new_cols[lag+2:]].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n",
    "    d2['pred'] = df[cols[lag]]\n",
    "    #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n",
    "    d3 = d2[~d2.duplicated(['key'], keep=False)]\n",
    "    return d1.merge(d3, how='left', on='key').pred.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', \n",
    "        'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', \n",
    "        '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867', \n",
    "        'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', \n",
    "        '1931ccfdd', '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', \n",
    "        '6619d81fc', '1db387535', \n",
    "        'fc99f9426', '91f701ba2', '0572565c2', '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98'\n",
    "       ]\n",
    "\n",
    "new_cols = ['c928b4b74','8e4d0fe45', '6c0e0801a', '02861e414',\n",
    "       'aac52d8d9', '041c5d0c9', 'd7875bb6c', 'e7c0cfd0f', 'd48c08bda',\n",
    "       '0c9462c08', '57dd44c29', 'a93118262', '850027e38', 'db3839ab0',\n",
    "       '27461b158', '32174174c', '9306da53f', '95742c2bf', '5831f4c76',\n",
    "       '1e6306c7c', '06393096a', '13bdd610a', 'd7d314edc', '9a07d7b1f',\n",
    "       '4d2671746', '822e49b95', '3c8a3ced0', '83635fb67', '1857fbccf',\n",
    "       'c4972742d', 'b6c0969a2', 'e78e3031b', '36a9a8479', 'e79e5f72c',\n",
    "       '092271eb3', '74d7f2dc3', '277ef93fc', 'b30e932ba', '8f57141ec',\n",
    "       '350473311']\n",
    "\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "train = train.drop(['target'],axis=1)\n",
    "train_and_test = pd.concat([train,test],axis=0)\n",
    "max_lag = 38\n",
    "total_leak =  train_and_test[['ID']].copy()\n",
    "for i in np.arange(max_lag):\n",
    "    c = \"leaked_target_\"+str(i)\n",
    "    total_leak[c] = _get_leak(train_and_test,cols,cols,i)\n",
    "for i in np.arange(max_lag):\n",
    "    c = \"leaked_target_\"+str(i+38)\n",
    "    total_leak[c] = _get_leak(train_and_test,new_cols,cols,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_leak = total_leak.drop(['ID'],axis=1)\n",
    "total_leak = total_leak.replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_leak['compiled_leak'] = np.nan\n",
    "for i in np.arange(max_lag):\n",
    "    c = total_leak['compiled_leak'].isna()\n",
    "    leak_target = 'leaked_target_'+str(i)\n",
    "    total_leak.loc[c,'compiled_leak'] = total_leak.loc[c,leak_target]\n",
    "\n",
    "total_leak['compiled_leak_new'] = np.nan\n",
    "for i in np.arange(max_lag):\n",
    "    c = total_leak['compiled_leak_new'].isna()\n",
    "    leak_target = 'leaked_target_'+str(i+38)\n",
    "    total_leak.loc[c,'compiled_leak_new'] = total_leak.loc[c,leak_target]\n",
    "# sum(train_leak['compiled_leak'] == train['target'])/sum(train_leak['compiled_leak'].notna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_leak_new = total_leak.loc[4459:]\n",
    "test_leak_new.to_csv('./test_leak_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_leak_new = total_leak.loc[:4459]\n",
    "train_leak_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
